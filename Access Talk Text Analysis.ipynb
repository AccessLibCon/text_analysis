{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Text Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from shutil import unpack_archive\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading our CSV files into a bunch of dataframes\n",
      "Loading...  1998\n",
      "Loading...  1999\n",
      "Loading...  2000\n",
      "Loading...  2001\n",
      "Loading...  2002\n",
      "Loading...  2003\n",
      "Loading...  2004\n",
      "Loading...  2005\n",
      "Loading...  2006\n",
      "Loading...  2007\n",
      "Loading...  2008\n",
      "Loading...  2009\n",
      "Loading...  2010\n",
      "Loading...  2011\n",
      "Loading...  2012\n",
      "Loading...  2013\n",
      "Loading...  2014\n",
      "Loading...  2015\n",
      "Loading...  2016\n",
      "Loading...  2017\n",
      "Loading...  2018\n",
      "Loading...  2019\n"
     ]
    }
   ],
   "source": [
    "# Load CSV Files\n",
    "print(\"Loading our CSV files into a bunch of dataframes\")\n",
    "df_dict = {}\n",
    "\n",
    "for f in sorted(os.listdir(os.curdir)):\n",
    "    if f.endswith('.csv'):\n",
    "        print(\"Loading... \",f[:-4])\n",
    "        df = pd.read_csv(f)\n",
    "        df_dict[f[:-4]] = df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many of the abstracts do we have?\n",
      "\n",
      "year,bad_abs,total_abs,percent\n",
      "1998 , 0 , 22 0.0\n",
      "1999 , 0 , 27 0.0\n",
      "2000 , 20 , 23 0.8695652173913043\n",
      "2001 , 19 , 26 0.7307692307692307\n",
      "2002 , 0 , 23 0.0\n",
      "2003 , 19 , 20 0.95\n",
      "2004 , 17 , 20 0.85\n",
      "2005 , 16 , 22 0.7272727272727273\n",
      "2006 , 0 , 27 0.0\n",
      "2007 , 17 , 21 0.8095238095238095\n",
      "2008 , 14 , 20 0.7\n",
      "2009 , 19 , 20 0.95\n",
      "2010 , 18 , 19 0.9473684210526315\n",
      "2011 , 14 , 15 0.9333333333333333\n",
      "2012 , 12 , 23 0.5217391304347826\n",
      "2013 , 22 , 25 0.88\n",
      "2014 , 19 , 20 0.95\n",
      "2015 , 22 , 22 1.0\n",
      "2016 , 25 , 27 0.9259259259259259\n",
      "2017 , 19 , 29 0.6551724137931034\n",
      "2018 , 18 , 24 0.75\n",
      "2019 , 28 , 28 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"how many of the abstracts do we have?\\n\")\n",
    "print(\"year,bad_abs,total_abs,percent\")\n",
    "\n",
    "\n",
    "for d in df_dict:\n",
    "    #print(\"\\nYear\",d,\"\\n\")\n",
    "    good_abs = 0\n",
    "    abs_count = len(df_dict[d].abstract)\n",
    "    for a in df_dict[d].abstract:\n",
    "        if type(a) == type(\"str\"):\n",
    "            good_abs +=1\n",
    "    #print(good_abs)\n",
    "    #print(abs_count,\" total abstracts\")\n",
    "    print(d,\",\",good_abs,\",\",abs_count, good_abs/abs_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
